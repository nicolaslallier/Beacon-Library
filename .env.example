# Backend Configuration
PYTHON_ENV=development
API_HOST=0.0.0.0
API_PORT=8000

# Database Configuration
POSTGRES_USER=beacon_user
POSTGRES_PASSWORD=beacon_password
POSTGRES_DB=beacon_library
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
DATABASE_URL=postgresql+asyncpg://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}

# Frontend Configuration
VITE_API_BASE_URL=http://localhost:8000

# Security (generate these in production)
SECRET_KEY=your-secret-key-here-change-in-production
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# File Storage
UPLOAD_DIR=./uploads
MAX_UPLOAD_SIZE=10485760

# =============================================================================
# Observability Configuration
# =============================================================================

# Environment label for all signals (local, dev, ppe, prod)
ENV=local

# Loki endpoint for log collection
LOKI_URL=http://loki.beacon.famillallier.net:3100

# Prometheus endpoint for metrics remote write
PROMETHEUS_URL=http://prometheus.beacon.famillallier.net:9090

# Tempo endpoint for trace export (gRPC)
TEMPO_URL=tempo.beacon.famillallier.net:4317

# OpenTelemetry configuration for backend
OTLP_ENDPOINT=http://alloy:4317
OTEL_TRACING_ENABLED=true
SERVICE_NAME=beacon-library-api
SERVICE_VERSION=0.1.0
LOG_LEVEL=INFO

# =============================================================================
# Authentication Configuration
# =============================================================================

# Enable authentication (set to false for development without Keycloak)
ENABLE_AUTH=false
VITE_ENABLE_AUTH=false

# Keycloak Configuration (only required if ENABLE_AUTH=true)
# Backend Keycloak URL (internal container network)
KEYCLOAK_URL=http://beacon-keycloak:8080
KEYCLOAK_REALM=beacon
KEYCLOAK_CLIENT_ID=beacon-library
KEYCLOAK_CLIENT_SECRET=

# Frontend Keycloak URL (must be accessible from browser)
VITE_KEYCLOAK_URL=https://keycloak.yourdomain.com
VITE_KEYCLOAK_REALM=beacon
VITE_KEYCLOAK_CLIENT_ID=beacon-library

# =============================================================================
# MCP (Model Context Protocol) Configuration
# =============================================================================

# Direct HTTP port for MCP API access (for local AI agents like LM Studio)
# This bypasses HTTPS/SSL for local network connections
MCP_PORT=8200

# MCP is enabled by default
MCP_ENABLED=true

# Rate limiting for MCP agents (requests per minute per agent)
MCP_RATE_LIMIT_REQUESTS=100
MCP_RATE_LIMIT_WINDOW=60

# Default write permission for MCP agents (false = read-only by default)
MCP_DEFAULT_WRITE_ENABLED=false

# =============================================================================
# Vector Search Optimization
# =============================================================================

# Chunk sizes for vector indexing (in tokens)
CHUNK_SIZE_CODE=1500
CHUNK_SIZE_DOCS=1000
CHUNK_OVERLAP=200
MAX_CHUNKS_PER_FILE=50

# Enable advanced code analysis (AST parsing, dependency extraction)
ENABLE_CODE_ANALYSIS=true

# ChromaDB Configuration
CHROMADB_HOST=chromadb
CHROMADB_PORT=8000

# Ollama Configuration (for embeddings)
OLLAMA_HOST=ollama
OLLAMA_PORT=11434
OLLAMA_EMBEDDING_MODEL=nomic-embed-text
